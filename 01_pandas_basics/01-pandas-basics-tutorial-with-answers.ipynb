{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='min'></a>\n",
    "[[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is based on [**10 minutes to pandas**](https://mybinder.org/v2/gh/TomAugspurger/pandas-binder/master?filepath=build%2Fjupyter%2Fgetting_started%2F10min.ipynb) with excercises added by @aniafijarczyk\n",
    "\n",
    "This is a short introduction to pandas, geared mainly for new users. \n",
    "You can see more complex recipes in the [Cookbook](https://pandas.pydata.org/docs/user_guide/cookbook.html).\n",
    "\n",
    "Customarily, we import as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutotrial is divided into 2 parts, each part followed by short excercises.\n",
    "### 1.  Reading and creating data frames\n",
    "- creating data frames\n",
    "- opening & viewing files\n",
    "- slicing, sorting, selecting rows and columns\n",
    "\n",
    "### 2. Describing and summarizing data frames\n",
    "- missing data\n",
    "- stats\n",
    "- merging, grouping\n",
    "- plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading and creating data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object creation\n",
    "\n",
    "See the [Data Structure Intro section](https://pandas.pydata.org/docs/user_guide/dsintro.html).\n",
    "\n",
    "Creating a `Series` by passing a list of values, letting pandas create\n",
    "a default integer index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a `DataFrame` by passing a NumPy array, with a datetime index\n",
    "and labeled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "dates\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a `DataFrame` by passing a dict of objects that can be converted to series-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'A': 1.,\n",
    "                    'B': pd.Timestamp('20130102'),\n",
    "                    'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "                    'D': np.array([3] * 4, dtype='int32'),\n",
    "                    'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "                    'F': 'foo'})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the resulting `DataFrame` have different\n",
    "[dtypes](https://pandas.pydata.org/docs/user_guide/basics.html#dtypes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re using IPython, tab completion for column names (as well as public\n",
    "attributes) is automatically enabled. Here’s a subset of the attributes that\n",
    "will be completed:\n",
    "\n",
    "As you can see, the columns `A`, `B`, `C`, and `D` are automatically\n",
    "tab completed. `E` is there as well; the rest of the attributes have been\n",
    "truncated for brevity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing data\n",
    "\n",
    "See the [Basics section](https://pandas.pydata.org/docs/user_guide/basics.html#).\n",
    "\n",
    "Here is how to view the top and bottom rows of the frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the index, columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.index\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dimentions of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_numpy()` gives a NumPy representation of the underlying data.\n",
    "Note that this can be an expensive operation when your `DataFrame` has\n",
    "columns with different data types, which comes down to a fundamental difference\n",
    "between pandas and NumPy: **NumPy arrays have one dtype for the entire array,\n",
    "while pandas DataFrames have one dtype per column**. When you call\n",
    "`DataFrame.to_numpy()`, pandas will find the NumPy dtype that can hold *all*\n",
    "of the dtypes in the DataFrame. This may end up being `object`, which requires\n",
    "casting every value to a Python object.\n",
    "\n",
    "For `df`, our `DataFrame` of all floating-point values,\n",
    "`DataFrame.to_numpy()` is fast and doesn’t require copying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `df2`, the `DataFrame` with multiple dtypes,\n",
    "`DataFrame.to_numpy()` is relatively expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note**\n",
    ">\n",
    ">`DataFrame.to_numpy()` does *not* include the index or column\n",
    "labels in the output.\n",
    "\n",
    "`describe()` shows a quick statistic summary of your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by an axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_index(axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='B',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection\n",
    "\n",
    ">**Note**\n",
    ">\n",
    ">While standard Python / Numpy expressions for selecting and setting are\n",
    "intuitive and come in handy for interactive work, for production code, we\n",
    "recommend the optimized pandas data access methods, `.at`, `.iat`,\n",
    "`.loc` and `.iloc`.\n",
    "\n",
    "See the indexing documentation [Indexing and Selecting Data](https://pandas.pydata.org/docs/user_guide/indexing.html) and [MultiIndex / Advanced Indexing](https://pandas.pydata.org/docs/user_guide/advanced.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting\n",
    "\n",
    "Selecting a single column, which yields a `Series`,\n",
    "equivalent to `df.A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting via `[]`, which slices the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[0:3]\n",
    "df['20130102':'20130104']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by label\n",
    "\n",
    "See more in [Selection by Label](https://pandas.pydata.org/docs/user_guide/indexing.html#selection-by-label).\n",
    "\n",
    "For getting a cross section using a label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[dates[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting on a multi-axis by label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, ['A','B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing label slicing, both endpoints are *included*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc['20130102':'20130104', ['A', 'B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduction in the dimensions of the returned object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc['20130102', ['A','B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For getting a scalar value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[dates[0], 'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For getting fast access to a scalar (equivalent to the prior method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.at[dates[0], 'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by position\n",
    "\n",
    "See more in [Selection by Position](https://pandas.pydata.org/docs/user_guide/indexing.html#selection-by-position).\n",
    "\n",
    "Select via the position of the passed integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By integer slices, acting similar to numpy/python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[3:5, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By lists of integer position locations, similar to the numpy/python style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[[1, 2, 4], [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For slicing rows explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[1:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For slicing columns explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For getting a value explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For getting fast access to a scalar (equivalent to the prior method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iat[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean indexing\n",
    "\n",
    "Using a single column’s values to select data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.A > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting values from a DataFrame where a boolean condition is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `isin()` method for filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2['E'] = ['one', 'one', 'two', 'three', 'four', 'three']\n",
    "df2\n",
    "df2[df2['E'].isin(['two', 'four'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting\n",
    "\n",
    "Setting a new column automatically aligns the data\n",
    "by the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range('20130102', periods=6))\n",
    "s1\n",
    "df['F'] = s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values by label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.at[dates[0], 'A'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values by position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iat[0, 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting by assigning with a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'D'] = np.array([5] * len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the prior setting operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `where` operation with setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[df2 > 0] = -df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data in/out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "\n",
    "[Writing to a csv file.](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-store-in-csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reading from a csv file.](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-read-csv-table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"gff_example.gff.gz\",compression=\"gzip\",comment=\"#\",sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel\n",
    "\n",
    "Reading and writing to [MS Excel](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#excel-files)\n",
    "\n",
    "[Writing](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#writing-excel-files) to an excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('foo.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reading](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#reading-excel-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "\n",
    "[Reading](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#reading-html-content) tables from html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"https://fungi.ensembl.org/species.html\"\n",
    "df_url = pd.read_html(url)\n",
    "df_url[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Writing](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#writing-to-html-files) tables to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_url[0].to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5\n",
    "\n",
    "Reading and writing to HDFStores.\n",
    "\n",
    "Writing to a HDF5 Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_hdf('foo.h5', 'df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a HDF5 Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_hdf('foo.h5', 'df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Csv blast file\n",
    "\n",
    "A. Read a text file with blast output (blast_example.tab) (watch there is no header)\n",
    "\n",
    "B. Change column names to \"query\", \"subject\", \"id\", \"length\", \"mismatches\", \"gaps\", \"qstart\", \"qstop\", \"sstart\", \"sstop\", \"eval\", \"bitscore\"\n",
    "\n",
    "C. Sort blast output by query ID, subject ID, lowest e-value, highest bitscore\n",
    "\n",
    "D. Check blast hits for queries: g12.t1, g13.t1 and g25.t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "# A. Read a text file with blast output\n",
    "df_blast = pd.read_csv(\"blast_example.tab\", sep = \"\\t\", header = None)\n",
    "df_blast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Change column names\n",
    "df_blast_columns =  [\"query\",\"subject\",\"id\",\"length\",\"mismatches\",\"gaps\",\"qstart\",\"qstop\",\"sstart\",\"sstop\",\"eval\",\"bitscore\"]\n",
    "df_blast.set_axis(df_blast_columns, axis=1, inplace=True)\n",
    "df_blast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Sort blast output by query ID, subject ID, lowest e-value, highest bitscore\n",
    "df_sort = df_blast.sort_values(by = [\"query\",\"subject\",\"eval\",\"bitscore\"],ascending=[True,True,True,False])\n",
    "df_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Check blast hits for queries: g12.t1, g13.t1 and g25.t1\n",
    "df_sort[((df_sort['query'] == \"g12.t1\") | (df_sort['query'] == \"g13.t1\") | (df_sort['query'] == \"g25.t1\"))]\n",
    "# or\n",
    "df_sort.loc[((df_sort['query'] == \"g12.t1\") | (df_sort['query'] == \"g13.t1\") | (df_sort['query'] == \"g25.t1\")),:]\n",
    "# shorter\n",
    "df_sort.loc[df_sort['query'].isin([\"g12.t1\",\"g13.t1\",\"g25.t1\"]),:]\n",
    "# or\n",
    "df_sort[df_sort['query'].isin([\"g12.t1\",\"g13.t1\",\"g25.t1\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel file\n",
    "\n",
    "A. Read data from excel table from sheet 1 (Table S1 in excel_examples.xlsx) (hint - use skiprows to skip top rows, same with the footer)\n",
    "\n",
    "B. Find cross names for which Species 1 is the same (intraspecific) or different from Species 2 (interspecific)\n",
    "\n",
    "C. Read data from excel table from sheet 2 - Table S2\n",
    "\n",
    "D. Calculate mean coverage at Tini for lines from intraspecific and interspecific crosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Read data from excel table from sheet 1\n",
    "df_sheet1 = pd.read_excel('excel_example.xlsx',sheet_name=\"Table S1\", skiprows=2, skipfooter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Cross names for which Species 1 is the same as Species 2\n",
    "intraspecific = df_sheet1.loc[(df_sheet1['Species 1'] == df_sheet1['Species 2']),'Cross']\n",
    "interspecific = df_sheet1.loc[(df_sheet1['Species 1'] != df_sheet1['Species 2']),'Cross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Read Table S2\n",
    "df_sheet2 = pd.read_excel('excel_example.xlsx',sheet_name=\"Table S2\", skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Mean coverage for intra and interspecific lines\n",
    "df_sheet2[df_sheet2['Cross'].isin(intraspecific)].describe().at['mean','Mean depth of coverage at Tini']\n",
    "df_sheet2[df_sheet2['Cross'].isin(interspecific)].describe().at['mean','Mean depth of coverage at Tini']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table from html\n",
    "\n",
    "A. Read tables from https://mycocosm.jgi.doe.gov/cgi-bin/kogBrowser?db=Ophnu1\n",
    "\n",
    "B. Remove first column and last row from the main tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Read tables\n",
    "df_html = pd.read_html(\"https://mycocosm.jgi.doe.gov/cgi-bin/kogBrowser?db=Ophnu1\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Remove 1st column and last row\n",
    "df_html[1].iloc[:-1,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vcf file\n",
    "\n",
    "A. Read vcf file (vcf_example.vcf.gz) (gzip compression)\n",
    "\n",
    "B. For a mutation in position (POS) 531245 on scaffold (#CHROM) utg69_pilon, check INFO field for DP (read depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Read vcf file\n",
    "# Skipping all comments\n",
    "df_vcf = pd.read_csv('vcf_example.vcf.gz',sep='\\t',compression=\"gzip\",comment=\"#\",header=None)\n",
    "# Skipping x lines but for this one need to know how many to skip\n",
    "df_vcf = pd.read_csv('vcf_example.vcf.gz',sep='\\t',compression=\"gzip\",skiprows=86,header=0)\n",
    "df_vcf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With standard open handle\n",
    "import io\n",
    "import os\n",
    "import gzip\n",
    "fh = gzip.open('vcf_example.vcf.gz','rt')\n",
    "lines = [l for l in fh if not l.startswith('##')]\n",
    "df_vcf = pd.read_csv(io.StringIO(''.join(lines)),sep='\\t')\n",
    "df_vcf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# B. mutation in position (POS) 531245 on scaffold (#CHROM) utg69_pilon, check INFO field\n",
    "df_vcf.loc[df_vcf['POS'] == 531245,\"INFO\"].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Describing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "pandas primarily uses the value `np.nan` to represent missing data. It is by\n",
    "default not included in computations. See the [Missing Data section](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html).\n",
    "\n",
    "Reindexing allows you to change/add/delete the index on a specified axis. This\n",
    "returns a copy of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[0]:dates[1], 'E'] = 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop any rows that have missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.dropna(how='any')\n",
    "df1.dropna(subset=[\"C\"],how='any')\n",
    "df1.dropna(axis=1,how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the boolean mask where values are `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.isna(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting rows with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[pd.isna(df1).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "See the [Basic section on Binary Ops](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#flexible-binary-operations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats\n",
    "\n",
    "Operations in general *exclude* missing data.\n",
    "\n",
    "Performing a [descriptive statistic](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#descriptive-statistics):\n",
    "\n",
    "count, sum, min, max, median, mean, prod, abs, std, var, sem, cumsum, quantile, ...\n",
    "\n",
    "sub, div, add, mul, divmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same operation on the other axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operating with objects that have different dimensionality and need alignment.\n",
    "In addition, pandas automatically broadcasts along the specified dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)\n",
    "s\n",
    "df.sub(s, axis=\"index\")\n",
    "df.sub(s, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "Applying functions to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.apply(np.cumsum)\n",
    "df.apply(lambda x: x.max() - x.min())\n",
    "df.apply(lambda x: np.quantile(x,0.1))\n",
    "df.quantile(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramming\n",
    "\n",
    "See more at [Histogramming and Discretization](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#value-counts-histogramming-mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randint(0, 7, size=10))\n",
    "s\n",
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Methods\n",
    "\n",
    "Series is equipped with a set of string processing methods in the str\n",
    "attribute that make it easy to operate on each element of the array, as in the\n",
    "code snippet below. Note that pattern-matching in str generally uses [regular\n",
    "expressions](https://docs.python.org/3/library/re.html) by default (and in\n",
    "some cases always uses them). See more at [Vectorized String Methods](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#vectorized-string-methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\n",
    "s.str.lower()\n",
    "s.str.lower().str.match('[a-z]*c[a-z]*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat\n",
    "\n",
    "pandas provides various facilities for easily combining together Series and\n",
    "DataFrame objects with various kinds of set logic for the indexes\n",
    "and relational algebra functionality in the case of join / merge-type\n",
    "operations.\n",
    "\n",
    "See the [Merging section](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#).\n",
    "\n",
    "Concatenating pandas objects together with `concat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "df\n",
    "\n",
    "# break it into pieces\n",
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "\n",
    "pd.concat(pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join\n",
    "\n",
    "SQL style merges. See the [Database style joining](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})\n",
    "left\n",
    "right\n",
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example that can be given is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\n",
    "left\n",
    "right\n",
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append\n",
    "\n",
    "Append rows to a dataframe. See the [Appending](user_guide/merging.ipynb#merging-concatenation)\n",
    "section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), columns=['A', 'B', 'C', 'D'])\n",
    "df\n",
    "s = df.iloc[3]\n",
    "df.append(s, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "By “group by” we are referring to a process involving one or more of the\n",
    "following steps:\n",
    "\n",
    "- **Splitting** the data into groups based on some criteria  \n",
    "- **Applying** a function to each group independently  \n",
    "- **Combining** the results into a data structure  \n",
    "\n",
    "\n",
    "\n",
    "See the [Grouping section](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#combining-with-stats-and-groupby)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\n",
    "                         'foo', 'bar', 'foo', 'foo'],\n",
    "                   'B': ['one', 'one', 'two', 'three',\n",
    "                         'two', 'two', 'one', 'three'],\n",
    "                   'C': np.random.randn(8),\n",
    "                   'D': np.random.randn(8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping and then applying the `sum()` function to the resulting\n",
    "groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('A').sum()\n",
    "df.groupby('A').size()\n",
    "df.groupby('A')['C'].sum()\n",
    "df.groupby('A').aggregate(np.sum)\n",
    "df.groupby('A').agg(np.sum)\n",
    "df.groupby('A').agg({'C':[np.min, np.max],'D':[np.mean,np.std]})\n",
    "df.groupby('A').agg({'C':['min', 'max'],'D':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by multiple columns forms a hierarchical index, and again we can\n",
    "apply the `sum` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['A', 'B']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "\n",
    "See the sections on [Hierarchical Indexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#hierarchical-indexing-multiindex) and\n",
    "[Reshaping](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#reshaping-by-pivoting-dataframe-objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n",
    "                     'foo', 'foo', 'qux', 'qux'],\n",
    "                    ['one', 'two', 'one', 'two',\n",
    "                     'one', 'two', 'one', 'two']]))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\n",
    "df2 = df[:4]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `stack()` method “compresses” a level in the DataFrame’s\n",
    "columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked = df2.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a “stacked” DataFrame or Series (having a `MultiIndex` as the\n",
    "`index`), the inverse operation of `stack()` is\n",
    "`unstack()`, which by default unstacks the **last level**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked.unstack()\n",
    "stacked.unstack(1)\n",
    "stacked.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot tables\n",
    "\n",
    "See the section on [Pivot Tables](user_guide/reshaping.ipynb#reshaping-pivot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,\n",
    "                   'B': ['A', 'B', 'C'] * 4,\n",
    "                   'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "                   'D': np.random.randn(12),\n",
    "                   'E': np.random.randn(12)})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can produce pivot tables from this data very easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melting\n",
    "\n",
    "See the section on [Metling](https://pandas.pydata.org/docs/user_guide/reshaping.html#reshaping-by-melt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C']).reset_index()\n",
    "df2\n",
    "pd.melt(df2, id_vars = ['A','B'], value_vars = ['bar','foo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "See the [Plotting](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(1000),\n",
    "               index=pd.date_range('1/1/2000', periods=1000))\n",
    "ts = ts.cumsum()\n",
    "\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a DataFrame, the `plot()` method is a convenience to plot all\n",
    "of the columns with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,\n",
    "                  columns=['A', 'B', 'C', 'D'])\n",
    "df = df.cumsum()\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['D'] = range(len(df))\n",
    "\n",
    "df.plot(x='D',y=['A','B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series\n",
    "\n",
    "pandas has simple, powerful, and efficient functionality for performing\n",
    "resampling operations during frequency conversion (e.g., converting secondly\n",
    "data into 5-minutely data). This is extremely common in, but not limited to,\n",
    "financial applications. See the [Time Series section](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = pd.date_range('1/1/2012', periods=100, freq='S')\n",
    "ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n",
    "ts.resample('5Min').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time zone representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')\n",
    "ts = pd.Series(np.random.randn(len(rng)), rng)\n",
    "ts\n",
    "ts_utc = ts.tz_localize('UTC')\n",
    "ts_utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to another time zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_utc.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between time span representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = pd.date_range('1/1/2012', periods=5, freq='M')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts\n",
    "ps = ts.to_period()\n",
    "ps\n",
    "ps.to_timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between period and timestamp enables some convenient arithmetic\n",
    "functions to be used. In the following example, we convert a quarterly\n",
    "frequency with year ending in November to 9am of the end of the month following\n",
    "the quarter end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')\n",
    "ts = pd.Series(np.random.randn(len(prng)), prng)\n",
    "ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categoricals\n",
    "\n",
    "pandas can include categorical data in a `DataFrame`. For full docs, see the\n",
    "[categorical introduction](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) and the API documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n",
    "                   \"raw_grade\": ['a', 'b', 'b', 'a', 'a', 'e']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the raw grades to a categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the categories to more meaningful names (assigning to\n",
    "`Series.cat.categories` is inplace!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"grade\"].cat.categories = [\"very good\", \"good\", \"very bad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the categories and simultaneously add the missing categories (methods under `Series\n",
    ".cat` return a new `Series` by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\", \"medium\",\n",
    "                                              \"good\", \"very good\"])\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting is per order in the categories, not lexical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=\"grade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by a categorical column also shows empty categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(\"grade\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gotchas\n",
    "\n",
    "If you are attempting to perform an operation you might see an exception like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    ">>> if pd.Series([False, True, False]):\n",
    "...     print(\"I was true\")\n",
    "Traceback\n",
    "    ...\n",
    "ValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Comparisons](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#comparing-objects) for an explanation and what to do.\n",
    "\n",
    "See [Gotchas](https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#gotchas) as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Csv blast file (sorted blast table from Ex. 1.1)\n",
    "\n",
    "A. For a sorted table group by query and select first best hit (check function [first](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.first.html))\n",
    "\n",
    "B. Plot histogram of identities (column id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Group by query and select first best hit\n",
    "df_besthit = df_sort.groupby(['query']).first()\n",
    "df_besthit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Plot histogram of \n",
    "df_besthit['id'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel tables\n",
    "\n",
    "A. Read Table S2, and for each 'Cross' check the min, max and mean Ploidy at Tend (groupby and agg).\n",
    "\n",
    "B. Plot histograms of ploidy (Ploidy at Tend) for each Cross.\n",
    "\n",
    "C. Read Table S4 and merge with Table S2 by 'Cross' and 'Line ID'\n",
    "\n",
    "D. Subset lines with Ploidy at Tend >2, and plot histogram of Copy number at Tend for the remaining crosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. In Table S2 group by column 'Cross' and check the min, max and mean ploidy at Tend\n",
    "df_sheet2.groupby(['Cross']).agg({'Ploidy at Tini':['min','max','mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Plot histograms of ploidy (Ploidy at Tend) for each cross\n",
    "df_sheet2['Ploidy at Tend'].hist(by=df_sheet2[\"Cross\"])\n",
    "# B shorter\n",
    "df_sheet2.groupby(['Cross']).hist('Ploidy at Tini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Read Table S4 and merge with Table S2 by 'Cross' and 'Line ID'\n",
    "df_sheet4 = pd.read_excel(\"excel_example.xlsx\",sheet_name=\"Table S4\", skiprows=2)\n",
    "df_merged = pd.merge(df_sheet2, df_sheet4, on = ['Cross','Line ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Subset lines with Ploidy at Tend >2, and plot histogram of Copy number at Tend in each cross\n",
    "df_subset = df_merged[df_merged['Ploidy at Tend']>2]\n",
    "df_subset.groupby(['Cross']).hist('Copy number at Tend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Html tables\n",
    "\n",
    "A. Concatenate main tables from  https://mycocosm.jgi.doe.gov/cgi-bin/kogBrowser?db=Ophnu1 and remove rows with Total Gene Count in column Function ID\n",
    "\n",
    "B. Do the same for another species https://mycocosm.jgi.doe.gov/cgi-bin/kogBrowser?db=Brefa1\n",
    "\n",
    "C. Merge two data frames by Function ID and plot a barplot on the whole data frame (.plot.bar())\n",
    "\n",
    "D. Melt table by species (one column with two variables = ophiostoma and bretziella, and gene count as value) and plot barplot\n",
    "\n",
    "E. Reshape table with pivot_table putting Function ID classes as column names and plot a barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Concatenate main tables from \n",
    "df_html = pd.read_html(\"https://mycocosm.jgi.doe.gov/cgi-bin/kogBrowser?db=Ophnu1\",header=0)\n",
    "df_concat = pd.concat(df_html[1:],ignore_index=True)\n",
    "df_concat = df_concat[df_concat['Function ID'] != 'Total Gene Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Concatenate tables from Bretziella\n",
    "df2_html = pd.read_html(\"https://mycocosm.jgi.doe.gov/cgi-bin/kogBrowser?db=Brefa1\",header=0)\n",
    "df2_concat = pd.concat(df2_html[1:],ignore_index=True)\n",
    "df2_concat = df2_concat[df2_concat['Function ID'] != 'Total Gene Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Merge two data frames by Function ID and plot a barplot on the whole data frame \n",
    "dmerged_concat = pd.merge(df_concat, df2_concat, on = ['Function ID'])\n",
    "dmerged_concat.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Melt table by species\n",
    "df_melt = pd.melt(dmerged_concat,id_vars = ['Function ID'],\n",
    "       value_vars = ['Gene Models inOphiostoma novo-ulmi subsp. novo-ulmi H327',\n",
    "                     'Gene Models inBretziella fagacearum C519 v1.0'])\n",
    "df_melt.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape table with pivot_table putting Function ID classes as column names\n",
    "df_pivot = pd.pivot_table(df_melt, index = 'variable', columns = 'Function ID', values = 'value')\n",
    "df_pivot.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel table\n",
    "\n",
    "A. Read data from excel table from sheet 5 with a list of de novo mutations\n",
    "\n",
    "B. Count number of A, C, T and G mutations for Scaffolds whose name starts with \"chr\" (you can use .str.match or str.startswith to select these scaffolds)\n",
    "\n",
    "C. Calculate mean number of A,C,T and G mutations across Scaffolds (remember to change NaN to 0)\n",
    "\n",
    "D. Write table with mutation counts (from B) to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Read data from excel table from sheet 5\n",
    "df_sheet5 = pd.read_excel('excel_example.xlsx',sheet_name=\"Table S5\", skiprows=2)\n",
    "df_sheet5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Count number of A, C, T and G mutations on Scaffolds whose name starts with \"chr\"\n",
    "df_chr = df_sheet5[df_sheet5['Scaffold'].str.match('chr')]\n",
    "df_group = df_chr.groupby(['Scaffold','Derived']).size()\n",
    "df_unstack = df_group.unstack()\n",
    "df_unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Calculate mean number of A,C,T and G mutations across selected Scaffolds\n",
    "df_unstack = df_unstack.fillna(0)\n",
    "df_unstack.apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Write table to tsv file.\n",
    "df_unstack.to_csv('df_unstack.tab',sep=\"\\t\",header=True,index=True)\n",
    "df_unstack.to_excel('df_unstack.xlsx')"
   ]
  }
 ],
 "metadata": {
  "filename": "10min.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "title": "10 minutes to pandas"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
