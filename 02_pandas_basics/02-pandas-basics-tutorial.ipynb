{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial in Basics of pandas #2 from [User Guide](https://pandas.pydata.org/docs/user_guide/index.html)\n",
    "@aniafijarczyk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional useful methods\n",
    "- correlations\n",
    "- ranking\n",
    "- rolling window\n",
    "- apply\n",
    "- groupby\n",
    "- groupby aggregate\n",
    "- groupby tranform\n",
    "- groupby filter\n",
    "- groupby apply\n",
    "- other useful features\n",
    "- Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "[Correlation](https://pandas.pydata.org/docs/user_guide/computation.html#correlation) may be computed using the corr() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.random.randn(1000, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "frame.iloc[::2] = np.nan\n",
    "frame\n",
    "frame[\"a\"].corr(frame[\"b\"])\n",
    "frame[\"a\"].corr(frame[\"b\"], method=\"spearman\")\n",
    "# Pairwise correlation of DataFrame columns\n",
    "frame.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ranking\n",
    "\n",
    "The rank() method produces a [data ranking](https://pandas.pydata.org/docs/user_guide/computation.html#data-ranking) with ties being assigned the mean of the ranks (by default) for the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(5), index=list(\"abcde\"))\n",
    "s[\"d\"] = s[\"b\"]  # so there's a tie\n",
    "s\n",
    "s.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 6))\n",
    "df[4] = df[2][:5]  # some ties\n",
    "df\n",
    "df.rank(0) # rows\n",
    "df.rank(1) # columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].apply(lambda x: x * (-1))\n",
    "df[0].apply(lambda x: x if x>0 else -x)\n",
    "df[0].apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[6] = df[0].apply(lambda x: 1 if x>0 else 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x[0]*x[1]*x[2]*x[3], axis=1)\n",
    "df.apply(lambda x: \"A\" if x[0]>x[1] else \"B\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling window\n",
    "\n",
    "Generic [rolling windows](https://pandas.pydata.org/docs/user_guide/window.html#rolling-window) support specifying windows as a fixed number of observations or variable number of observations based on an offset. If a time based offset is provided, the corresponding time based index must be monotonic. Rolling window [functions](https://pandas.pydata.org/docs/reference/window.html#api-functions-rolling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ['2020-01-01', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-29']\n",
    "s = pd.Series(range(5), index=pd.DatetimeIndex(times))\n",
    "s\n",
    "# Window with 2 observations\n",
    "s.rolling(window=2).sum()\n",
    "\n",
    "# Window with 2 days worth of observations\n",
    "s.rolling(window='2D').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the labels are set to the right edge of the window, but a center keyword is available so the labels can be set at the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(range(10))\n",
    "s.rolling(window=5).mean()\n",
    "s.rolling(window=5, center=True).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inclusion of the interval endpoints in rolling window calculations can be specified with the closed parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"x\": 1},\n",
    "    index=[\n",
    "        pd.Timestamp(\"20130101 09:00:01\"),\n",
    "        pd.Timestamp(\"20130101 09:00:02\"),\n",
    "        pd.Timestamp(\"20130101 09:00:03\"),\n",
    "        pd.Timestamp(\"20130101 09:00:04\"),\n",
    "        pd.Timestamp(\"20130101 09:00:06\"),\n",
    "    ])\n",
    "\n",
    "df[\"right\"] = df.rolling(\"2s\", closed=\"right\").x.sum()  # default\n",
    "df[\"both\"] = df.rolling(\"2s\", closed=\"both\").x.sum()\n",
    "df[\"left\"] = df.rolling(\"2s\", closed=\"left\").x.sum()\n",
    "df[\"neither\"] = df.rolling(\"2s\", closed=\"neither\").x.sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby \n",
    "Creating [groupby](https://pandas.pydata.org/docs/user_guide/groupby.html#) object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n",
    "        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n",
    "        \"C\": np.random.randn(8),\n",
    "        \"D\": np.random.randn(8),\n",
    "    }\n",
    ")\n",
    "df.groupby(\"A\")\n",
    "df.groupby(\"A\").groups\n",
    "df.groupby(\"A\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a single group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"A\").get_group('foo')\n",
    "df.groupby([\"A\",\"B\"]).get_group(('foo','one'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby with MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [\n",
    "    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n",
    "    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\"])\n",
    "df2 = pd.DataFrame({\"A\": [1, 1, 1, 1, 2, 2, 3, 3], \"B\": np.arange(8)}, index=index)\n",
    "df2\n",
    "\n",
    "df2.groupby(level=1).sum()\n",
    "df2.groupby(level=\"second\").sum()\n",
    "df2.groupby(\"second\").sum()\n",
    "df2.groupby([\"first\",\"second\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby with index levels and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby([pd.Grouper(level=1), \"A\"]).sum()\n",
    "df2.groupby([\"second\",\"A\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"A\")[\"C\"].sum()\n",
    "df.groupby(\"A\")[\"D\",\"C\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterationg through groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df2.groupby(\"A\"):\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby aggregate\n",
    "\n",
    "Once the GroupBy object has been created, several methods are available to perform a computation on the grouped data. An obvious one is aggregation via the [aggregate()](https://pandas.pydata.org/docs/user_guide/groupby.html#aggregation) or equivalently agg() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n",
    "        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n",
    "        \"C\": np.random.randn(8),\n",
    "        \"D\": np.random.randn(8),\n",
    "    })\n",
    "df.groupby([\"A\", \"B\"]).sum()\n",
    "df.groupby([\"A\", \"B\"]).aggregate(np.sum)\n",
    "df.groupby([\"A\", \"B\"]).agg(np.sum)\n",
    "df.groupby([\"A\", \"B\"]).agg(\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"A\", \"B\"], as_index=False).agg(np.sum)\n",
    "# or\n",
    "df.groupby([\"A\", \"B\"]).agg(np.sum).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic [aggregating functions](https://pandas.pydata.org/docs/user_guide/groupby.html#aggregation) on groupby objects\n",
    "\n",
    "size() returns a Series whose index are the group names and whose values are the sizes of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"A\", \"B\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"A\", \"B\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of unique values of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"A\"]).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some common aggregations, currently only sum, mean, std, and sem, have optimized Cython implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"A\", \"B\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying user defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('A').agg(lambda x: 1)\n",
    "df.groupby('A').agg(lambda x: x.sum())\n",
    "df.groupby('A').agg(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = pd.DataFrame(\n",
    "    {   \"kind\": [\"cat\", \"dog\", \"cat\", \"dog\"],\n",
    "        \"height\": [9.1, 6.0, 9.5, 34.0],\n",
    "        \"weight\": [7.9, 7.5, 9.9, 198.0],\n",
    "    })\n",
    "animals.groupby(\"kind\")[[\"height\"]].agg(lambda x: set(x))\n",
    "animals.groupby(\"kind\")[[\"height\"]].agg(lambda x: x.astype(int).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying multiple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"A\")[\"C\"].agg([np.sum, np.mean, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.groupby(\"A\")[\"C\"]\n",
    "    .agg([np.sum, np.mean, np.std])\n",
    "    .rename(columns={\"sum\": \"foo\", \"mean\": \"bar\", \"std\": \"baz\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple functions on different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"A\")[\"C\"].agg([lambda x: x.max() - x.min(),\n",
    "                          lambda x: x.median() - x.mean()])\n",
    "df.groupby(\"A\").agg({\"C\" : [lambda x: x.max() - x.min(),\n",
    "                            lambda x: x.median() - x.mean()]})\n",
    "df.groupby(\"A\").agg({\"C\" : [lambda x: x.max() - x.min()],\n",
    "                     \"D\" : [np.mean,np.std]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [named aggregation](https://pandas.pydata.org/docs/user_guide/groupby.html#named-aggregation) - you can name columns yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = df.groupby(\"A\").agg(span_C = pd.NamedAgg(column = \"C\", aggfunc = lambda x: x.max() - x.min()),\n",
    "                         mean_D = pd.NamedAgg(column = \"D\", aggfunc = np.mean),\n",
    "                         std_D = pd.NamedAgg(column = \"D\", aggfunc = np.std))\n",
    "\n",
    "# same as\n",
    "g2 = df.groupby(\"A\").agg(span_C = (\"C\", lambda x: x.max() - x.min()),\n",
    "                         mean_D = (\"D\", np.mean),\n",
    "                         std_D = (\"D\", np.std))\n",
    "\n",
    "# or for a single column\n",
    "g3 = df.groupby(\"A\")[\"C\"].agg(span_C = lambda x: x.max() - x.min())\n",
    "\n",
    "g1\n",
    "g2\n",
    "g3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby transform\n",
    "\n",
    "The [transform](https://pandas.pydata.org/docs/user_guide/groupby.html#transformation) method returns an object that is indexed the same (same size) as the one being grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range(\"10/1/1999\", periods=1100)\n",
    "ts = pd.Series(np.random.normal(0.5, 2, 1100), index)\n",
    "ts = ts.rolling(window=100, min_periods=100).mean().dropna()\n",
    "\n",
    "transformed = ts.groupby(lambda x: x.year).transform(\n",
    "    lambda x: (x - x.mean()) / x.std())\n",
    "transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation functions that have lower dimension outputs are broadcast to match the shape of the input array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = ts.groupby(lambda x: x.year).transform(\"max\")\n",
    "min = ts.groupby(lambda x: x.year).transform(\"min\")\n",
    "max - min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing missing data with group mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame({\"A\":np.random.normal(0, 1, 1000),\n",
    "                       \"B\":np.random.normal(0, 1, 1000),\n",
    "                       \"C\":np.random.normal(0, 1, 1000)})\n",
    "data_df['C'][data_df['C']<0] = np.nan\n",
    "data_df\n",
    "\n",
    "countries = np.array([\"US\", \"UK\", \"GR\", \"JP\"])\n",
    "key = countries[np.random.randint(0, 4, 1000)]\n",
    "grouped = data_df.groupby(key)\n",
    "grouped.count()\n",
    "\n",
    "transformed = grouped.transform(lambda x: x.fillna(x.mean()))\n",
    "transformed.head()\n",
    "transformed.groupby(key).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Window and resample operations](https://pandas.pydata.org/docs/user_guide/groupby.html#window-and-resample-operations)\n",
    "\n",
    "Getting mean of 4 previous elements with rolling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re = pd.DataFrame({\"A\": [1] * 10 + [5] * 10, \"B\": np.arange(20)})\n",
    "df_re\n",
    "df_re.groupby(\"A\").rolling(4).B.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expanding() method will accumulate a given operation (sum() in the example) for all the members of each particular group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re.groupby(\"A\").expanding().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can to use the resample() method to get a daily frequency in each group of your dataframe and complete the missing values with the ffill() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re = pd.DataFrame({\"date\": pd.date_range(start=\"2016-01-01\", periods=4, freq=\"W\"),\n",
    "                      \"group\": [1, 1, 2, 2],\n",
    "                      \"val\": [5, 6, 7, 8]}).set_index(\"date\")\n",
    "df_re\n",
    "df_re.groupby(\"group\").resample(\"1D\").ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby filter\n",
    "\n",
    "The [filter](https://pandas.pydata.org/docs/user_guide/groupby.html#filtration) method returns a subset of the original object\n",
    "\n",
    "Take only elements that belong to groups with a group sum greater than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = pd.Series([1, 1, 2, 3, 3, 3])\n",
    "sf.groupby(sf).filter(lambda x: x.sum() > 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out elements that belong to groups with only a couple members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame({\"A\": np.arange(8), \"B\": list(\"aabbbbcc\")})\n",
    "dff.groupby(\"B\").filter(lambda x: len(x) > 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return a like-indexed objects where the groups that do not pass the filter are filled with NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupby(\"B\").filter(lambda x: len(x) > 2, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DataFrames with multiple columns, filters should explicitly specify a column as the filter criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"C\"] = np.arange(8)\n",
    "dff.groupby(\"B\").filter(lambda x: len(x[\"C\"]) > 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nlargest and nsmallest methods work on Series style groupbys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([9, 8, 7, 5, 19, 1, 4.2, 3.3])\n",
    "g = pd.Series(list(\"abababab\"))\n",
    "gb = s.groupby(g)\n",
    "gb.nlargest(1)\n",
    "gb.nsmallest(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby apply\n",
    "\n",
    "[Apply](https://pandas.pydata.org/docs/user_guide/groupby.html#flexible-apply) function can be substituted for both aggregate and transform in many standard use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n",
    "        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n",
    "        \"C\": np.random.randn(8),\n",
    "        \"D\": np.random.randn(8),\n",
    "    })\n",
    "\n",
    "# output is a series\n",
    "df.groupby(\"A\")[\"C\"].apply(lambda x: x.describe())\n",
    "# or (output is a dataframe)\n",
    "df.groupby(\"A\").apply(lambda x: x[\"C\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations with multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"A\").apply(lambda x: x[\"C\"] + x[\"D\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(group):\n",
    "    return pd.DataFrame({'original': group,\n",
    "                         'demeaned': group - group.mean()})\n",
    "\n",
    "df.groupby('A')['C'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return pd.Series([x, x ** 2], index=[\"x\", \"x^2\"])\n",
    "s = pd.Series(np.random.rand(5))\n",
    "s.apply(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the first or the last rows of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"A\").head(1) # first\n",
    "df.groupby(\"A\").tail(1) # last\n",
    "df.groupby(\"A\").nth(0) # first\n",
    "df.groupby(\"A\").nth(-1) # last\n",
    "df.groupby(\"A\").first() # first\n",
    "df.groupby(\"A\").last() # last\n",
    "df.groupby(\"A\").nth(-1,dropna=\"any\") # last excluding NaN\n",
    "df.groupby(\"A\").nth([0,-1]) # first and last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the order in which each row appears within its group, use the cumcount method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = pd.DataFrame(list(\"aaabba\"), columns=[\"A\"])\n",
    "dfg.groupby(\"A\").cumcount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the ordering of the groups you can use ngroup(). The numbers given to the groups match the order in which the groups would be seen when iterating over the groupby object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.groupby(\"A\").ngroup()\n",
    "dfg.groupby(\"A\").ngroup(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "df = pd.DataFrame(np.random.randn(50, 2))\n",
    "df[\"g\"] = np.random.choice([\"A\", \"B\"], size=50)\n",
    "\n",
    "# adding 3 to each element in column 1 if it belongs to group B in g column\n",
    "df.loc[df[\"g\"] == \"B\", 1] += 3\n",
    "df.groupby(\"g\").boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Piping](https://pandas.pydata.org/docs/user_guide/groupby.html#piping-function-calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Store\": np.random.choice([\"Store_1\", \"Store_2\"], n),\n",
    "        \"Product\": np.random.choice([\"Product_1\", \"Product_2\"], n),\n",
    "        \"Revenue\": (np.random.random(n) * 50 + 10).round(2),\n",
    "        \"Quantity\": np.random.randint(1, 10, size=n)})\n",
    "\n",
    "df.groupby([\"Store\", \"Product\"]).pipe(lambda x: x['Revenue'].sum() / x['Quantity'].sum()).unstack().round(2)\n",
    "df.groupby([\"Store\", \"Product\"]).pipe(lambda x: x['Revenue'].sum() / x['Quantity'].sum())\n",
    "df.groupby([\"Store\", \"Product\"]).pipe(lambda x: x.mean())\n",
    "df.groupby([\"Store\", \"Product\"]).apply(lambda x: x['Revenue'].sum() / x['Quantity'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regrouping columns of a DataFrame according to their sum, and summing the aggregated ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"a\": [1, 0, 0], \"b\": [0, 1, 0], \"c\": [1, 0, 0], \"d\": [2, 3, 4]})\n",
    "df.groupby(df.sum(),axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby by indexer to ‘resample’ data.\n",
    "\n",
    "Grouping data into bins of 5 (df.index // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 2))\n",
    "df.index // 5\n",
    "df.groupby(df.index // 5).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Group DataFrame columns, compute a set of metrics and return a named Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],\n",
    "        \"b\": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
    "        \"c\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "        \"d\": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],})\n",
    "def compute_metrics(x):\n",
    "    result = {\"b_sum\": x[\"b\"].sum(), \"c_mean\": x[\"c\"].mean()}\n",
    "    return pd.Series(result, name=\"metrics\")\n",
    "result = df.groupby(\"a\").apply(compute_metrics)\n",
    "result\n",
    "result.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excel table S2**\n",
    "\n",
    "Calculate correlation between coverage (Tend) and ploidy (Tend) per each cross and plot scatterplot of two variables in each cross (function corr() with groupby calculates pairwise correlations for all pairs of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excel table S4**\n",
    "\n",
    "For each Cross and Scaffold calculate mean mutation rate: N mutations/(Length (bp) x copy number * N generations)\n",
    "\n",
    "Either 1) get rate per line -> group -> get mean,\n",
    "or 2) group -> calculate rate on summed mutations and lengths. \n",
    "Some lines have length == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excel table S2**\n",
    "\n",
    "Calculate Z-scores for 'Mean depth of coverage at Tini' ( (x - x.mean())/x.std() ) standardized across each cross and add to dataframe as a new column 'z-score' (use transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excel table S5**\n",
    "\n",
    "Calculate Ts/Tv for each cross and plot as a barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
